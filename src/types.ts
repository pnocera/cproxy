#!/usr/bin/env node

/**
 * Comprehensive Type Definitions for cproxy TypeScript Conversion
 * Generated by Hive Mind Collective Intelligence System
 */

import { FastifyRequest, FastifyReply } from 'fastify';
import { IncomingMessage, ServerResponse } from 'http';

// ==================== ENVIRONMENT CONFIGURATION ====================

export interface EnvironmentConfig {
  ANTHROPIC_PROXY_BASE_URL?: string;
  OPENROUTER_API_KEY?: string;
  REASONING_MODEL?: string;
  COMPLETION_MODEL?: string;
  DEBUG?: string;
  PORT?: string;
}

export interface ProxyConfig {
  baseUrl: string;
  requiresApiKey: boolean;
  key: string | null;
  model: string;
  models: {
    reasoning: string;
    completion: string;
  };
}

// ==================== ANTHROPIC CLAUDE API TYPES ====================

export type AnthropicRole = 'user' | 'assistant' | 'system';

export interface AnthropicTextContent {
  type: 'text';
  text: string;
}

export interface AnthropicToolUse {
  type: 'tool_use';
  id: string;
  name: string;
  input: Record<string, any>;
}

export interface AnthropicToolResult {
  type: 'tool_result';
  tool_use_id: string;
  content?: string;
  text?: string;
  is_error?: boolean;
}

export type AnthropicContent = AnthropicTextContent | AnthropicToolUse | AnthropicToolResult;

export interface AnthropicMessage {
  role: AnthropicRole;
  content: string | AnthropicContent[];
}

export interface AnthropicSystemMessage {
  text?: string;
  content?: string;
}

export interface AnthropicTool {
  name: string;
  description: string;
  input_schema: Record<string, any>;
}

export interface AnthropicRequest {
  model?: string;
  messages: AnthropicMessage[];
  system?: AnthropicSystemMessage[];
  tools?: AnthropicTool[];
  max_tokens?: number;
  temperature?: number;
  stream?: boolean;
  thinking?: boolean;
}

export interface AnthropicUsage {
  input_tokens: number;
  output_tokens: number;
}

export type AnthropicStopReason = 'end_turn' | 'max_tokens' | 'stop_sequence' | 'tool_use';

export interface AnthropicResponse {
  id: string;
  type: 'message';
  role: 'assistant';
  model: string;
  content: AnthropicContent[];
  stop_reason: AnthropicStopReason;
  stop_sequence: string | null;
  usage: AnthropicUsage;
}

// ==================== OPENAI API TYPES ====================

export type OpenAIRole = 'system' | 'user' | 'assistant' | 'tool';

export interface OpenAIMessage {
  role: OpenAIRole;
  content?: string;
  tool_calls?: OpenAIToolCall[];
  tool_call_id?: string;
}

export interface OpenAIToolCall {
  id: string;
  type?: string;
  function: {
    type?: string;
    id?: string;
    function?: {
      name: string;
      parameters: Record<string, any>;
    };
    name: string;
    arguments: string;
  };
}

export interface OpenAITool {
  type: 'function';
  function: {
    name: string;
    description: string;
    parameters: Record<string, any>;
  };
}

export interface OpenAIRequest {
  model: string;
  messages: OpenAIMessage[];
  tools?: OpenAITool[];
  max_tokens?: number;
  temperature?: number;
  stream: boolean;
}

export interface OpenAIUsage {
  prompt_tokens: number;
  completion_tokens: number;
  total_tokens?: number;
}

export interface OpenAIChoice {
  index?: number;
  message: OpenAIMessage;
  finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter';
  delta?: {
    content?: string;
    reasoning?: string;
    tool_calls?: OpenAIToolCall[];
  };
}

export interface OpenAIResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: OpenAIChoice[];
  usage?: OpenAIUsage;
  error?: {
    message: string;
    type: string;
    code?: string;
  };
}

// ==================== STREAMING TYPES ====================

export type SSEEventType = 
  | 'message_start'
  | 'message_delta' 
  | 'message_stop'
  | 'content_block_start'
  | 'content_block_delta'
  | 'content_block_stop'
  | 'ping';

export interface SSEMessageStart {
  type: 'message_start';
  message: {
    id: string;
    type: 'message';
    role: 'assistant';
    model: string;
    content: AnthropicContent[];
    stop_reason: AnthropicStopReason | null;
    stop_sequence: string | null;
    usage: AnthropicUsage;
  };
}

export interface SSEMessageDelta {
  type: 'message_delta';
  delta: {
    stop_reason: AnthropicStopReason;
    stop_sequence: string | null;
  };
  usage?: {
    output_tokens: number;
  };
}

export interface SSEMessageStop {
  type: 'message_stop';
}

export interface SSEContentBlockStart {
  type: 'content_block_start';
  index: number;
  content_block: {
    type: 'text' | 'tool_use';
    id?: string;
    name?: string;
    text?: string;
    input?: Record<string, any>;
  };
}

export interface SSEContentBlockDelta {
  type: 'content_block_delta';
  index: number;
  delta: {
    type: 'text_delta' | 'input_json_delta' | 'thinking_delta';
    text?: string;
    partial_json?: string;
    thinking?: string;
  };
}

export interface SSEContentBlockStop {
  type: 'content_block_stop';
  index: number;
}

export interface SSEPing {
  type: 'ping';
}

export type SSEEvent = 
  | SSEMessageStart 
  | SSEMessageDelta 
  | SSEMessageStop
  | SSEContentBlockStart
  | SSEContentBlockDelta
  | SSEContentBlockStop
  | SSEPing;

// ==================== UTILITY TYPES ====================

export interface ToolCallAccumulator {
  [key: number]: string;
}

export interface NormalizedContent {
  text?: string;
  content?: string;
}

export interface ErrorResponse {
  error: string;
}

export type FinishReason = 'tool_calls' | 'stop' | 'length' | string;

// ==================== FASTIFY REQUEST/RESPONSE TYPES ====================

export interface ProxyRequest extends FastifyRequest {
  body: AnthropicRequest;
}

export interface ProxyReply extends FastifyReply {
  raw: ServerResponse;
}

// ==================== FUNCTION TYPES ====================

export type ContentNormalizer = (content: string | NormalizedContent[]) => string | null;
export type StopReasonMapper = (finishReason: FinishReason) => AnthropicStopReason;
export type SchemaProcessor = (schema: any) => any;
export type SSESender = (reply: FastifyReply, event: SSEEventType, data: SSEEvent) => void;
export type DebugLogger = (...args: any[]) => void;

// ==================== JSON SCHEMA TYPES ====================

export interface JSONSchema {
  type?: string;
  format?: string;
  properties?: Record<string, JSONSchema>;
  items?: JSONSchema;
  additionalProperties?: JSONSchema | boolean;
  anyOf?: JSONSchema[];
  allOf?: JSONSchema[];
  oneOf?: JSONSchema[];
  [key: string]: any;
}

// ==================== HTTP TYPES ====================

export interface RequestHeaders {
  'Content-Type': string;
  'Authorization'?: string;
}

export interface ResponseHeaders {
  'Content-Type': string;
  'Cache-Control'?: string;
  'Connection'?: string;
}

// ==================== STREAMING READER TYPES ====================

export interface StreamReader {
  value: Uint8Array | undefined;
  done: boolean;
}

export interface StreamingState {
  accumulatedContent: string;
  accumulatedReasoning: string;
  usage: OpenAIUsage | null;
  textBlockStarted: boolean;
  encounteredToolCall: boolean;
  toolCallAccumulators: ToolCallAccumulator;
  messageId: string;
}

// ==================== SERVER TYPES ====================

export interface ServerConfig {
  logger: boolean;
}

export interface ListenOptions {
  port: number;
}

// ==================== TYPE GUARDS ====================

export const isAnthropicContent = (content: any): content is AnthropicContent[] => {
  return Array.isArray(content) && content.every(item => 
    typeof item === 'object' && 'type' in item
  );
};

export const isToolUse = (item: any): item is AnthropicToolUse => {
  return item && item.type === 'tool_use' && 'id' in item && 'name' in item;
};

export const isToolResult = (item: any): item is AnthropicToolResult => {
  return item && item.type === 'tool_result' && 'tool_use_id' in item;
};

export const isTextContent = (item: any): item is AnthropicTextContent => {
  return item && item.type === 'text' && 'text' in item;
};

// ==================== CONSTANTS ====================

export const DEFAULT_MODEL = 'google/gemini-2.0-pro-exp-02-05:free';
export const DEFAULT_BASE_URL = 'https://openrouter.ai/api';
export const DEFAULT_PORT = 3000;
export const EXCLUDED_TOOLS = ['BatchTool'];

// ==================== EXPORT ALL TYPES ====================

export type {
  FastifyRequest,
  FastifyReply,
  IncomingMessage,
  ServerResponse
};